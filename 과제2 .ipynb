{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 유출 문제로 인해 , 데이터 없이 코드만 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import re\n",
    "import gensim # Word2Vec\n",
    "from konlpy.tag import Mecab  # 형태소 분석기\n",
    "m = Mecab()\n",
    "\n",
    "\n",
    "#시각화 한글폰트 사용\n",
    "import matplotlib            \n",
    "matplotlib.font_manager._rebuild()         \n",
    "plt.rcParams[\"font.family\"] = 'NanumGothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터프레임 생성 및 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refineDataFrame(df):\n",
    "    \n",
    "    #정규표현식 및 , 양 끝 공백 제거\n",
    "    re_pattern = re.compile(r'[^ 가-힣a-zA-Z0-9]')\n",
    "    df['적요'] = df['적요'].apply(lambda x : re.sub(pattern = re_pattern, repl = '', string = str(x)))\n",
    "    df['적요'] = df['적요'].apply(lambda x : x.strip())\n",
    "    \n",
    "    \n",
    "    #mecab 형태소분석기를 사용하여 명사 추출 \n",
    "    m = Mecab()\n",
    "    df['적요Noun'] = df['적요'].apply(lambda x : m.nouns(x))\n",
    "    \n",
    "    \n",
    "    #index 초기화\n",
    "    df = df.reset_index()\n",
    "    df.drop(['Unnamed: 0', 'index'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataFrame():\n",
    "    \n",
    "    #디렉토리를 아래와 같이 설정\n",
    "    dirPath = '/home/jovyan/WIDE_HOME/Competition/data/경진대회데이터/품목적요데이터'\n",
    "    if os.getcwd() != dirPath:\n",
    "        os.chdir(dirPath)\n",
    "\n",
    "    # 적요 데이터프레임 담을 빈 데이터프레임 생성    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    #모든 csv 하나의 데이터프레임으로 결합\n",
    "    for i in tqdm([csv for csv in os.listdir() if'적요' in csv]):\n",
    "        df = df.append(pd.read_csv(i), ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "def refineDataFrame(df):\n",
    "    # 적요 데이터 정제\n",
    "    df['적요'] = df['적요'].apply(lambda x : x.strip())\n",
    "    df = df[(df['적요'] != '') & (df['적요'] != '외') & (df['적요'] != '등')]\n",
    "    \n",
    "\n",
    "    df['적요'] = df['적요'].apply(lambda x : x.strip())\n",
    "    \n",
    "    re_pattern = re.compile(r'[^ 가-힣a-zA-Z0-9]')\n",
    "    df['적요'] = df['적요'].apply(lambda x : re.sub(pattern = re_pattern, repl = '', string = str(x)))\n",
    "    df = df[(df['적요'] != '') & (df['적요'] != '외') & (df['적요'] != '등')]\n",
    "    \n",
    "    \n",
    "    print('전처리 진행중 . . . ')\n",
    "    df['적요Noun'] = df['적요'].apply(lambda x : m.nouns(x))\n",
    "    df = df.reset_index()\n",
    "    df.drop(['Unnamed: 0', 'index'], axis = 1, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = makeDataFrame()\n",
    "df = refineDataFrame(df)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <center>업종별 특성 EDA </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "\n",
    "def mostCommonPlot(df, title):\n",
    "    nounList = [i for i in df['적요Noun'].values]\n",
    "    counter = collections.Counter([x for sublist in nounList for x in sublist])\n",
    "    mostCommon = pd.DataFrame(counter.most_common(30))\n",
    "    mostCommon.index = mostCommon[0]\n",
    "    mostCommon.drop(0, axis = 1 , inplace = True)\n",
    "\n",
    "    mostCommon.plot(kind = 'bar', figsize = (24,8))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "mostCommonPlot(df, title = '전체 데이터프레임 적요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nounList = [i for i in df['적요Noun'].values]\n",
    "\n",
    "[i.remove('등') for i in nounList if '등' in i]\n",
    "[i.remove('외') for i in nounList if '외' in i]\n",
    "\n",
    "nounList = [i for i in df['적요Noun'].values]\n",
    "counter = collections.Counter([x for sublist in nounList for x in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 12))\n",
    "a = sns.countplot(y='판매구매자_업종대분류', data=df, order = df['판매구매자_업종대분류'].value_counts().index)\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=45)\n",
    "plt.title('판매구매자_업종대분류 value counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (24,18))\n",
    "\n",
    "a = sns.countplot(y ='판매구매자_업종중분류', data=df, order = df['판매구매자_업종중분류'].value_counts().head(50).index)\n",
    "#plt.axhline(8.5, color = 'r')\n",
    "plt.title('판매구매자_업종중분류 value counts')\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업종중분류 중 , 가장 많은 비중을 차지하는 10개만 시각화를 통해 , 자주 나오는 적요 EDA\n",
    "\n",
    "for midCateogry in df['판매구매자_업종중분류'].value_counts().head(10).index:\n",
    "    mostCommonPlot(df[df['판매구매자_업종중분류'] == midCateogry], title = midCateogry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <center>학습 데이터 생성</center>\n",
    "- mecab Library를 통해 생성한 적요Noun가 5개 이상이면 , 학습데이터로 사용하기로 함\n",
    "- 구매/판매구분이 1이면 , 업종소분류도 유의미한 정보라고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordOver5 = df[df['적요Noun'].apply(lambda x : True if len(x) >=5 else False)]\n",
    "wordOver5['적요Noun']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 매출은 , 업종별 적요의 특성을 잘 나타내줌\n",
    "- Embedding 모델인 FastText의 파라미터인 window값은 5로 설정하여 , 5 음절 이상의 단어를 학습데이터로 사용하였습니다.\n",
    "- 학습 데이터에 구매판매구분이 1 이면 , 해당 적요는 업종과 상당히 유사성이 큰 의미를 갖는다고 생각하여 , 업종소분류의 이름도 추가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "saleSent = (wordOver5[wordOver5['구매/판매구분']==1]['판매구매자_업종소분류'] + wordOver5[wordOver5['구매/판매구분']==1]['적요']).apply(lambda x : x.split(' '))\n",
    "incomeSent = wordOver5[wordOver5['구매/판매구분']==2]['적요Noun']\n",
    "\n",
    "useDataSent = pd.concat([saleSent, incomeSent] , ignore_index = True)\n",
    "\n",
    "model = FastText(sentences = useDataSent, window = 5)\n",
    "\n",
    "useDataSent.tail(10)\n",
    "\n",
    "\n",
    "\n",
    "# 램 용량을 최대한 많이 활용하고자 삭제\n",
    "del wordOver5 , saleSent, incomeSent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 부족한부분 네이버사전에서 Crawling을 통해 csv 생성 후 학습용데이터로 Load\n",
    "- WikiPedia 데이터도 가져올 수 있었지만 , 해당 데이터의 Embedding을 위한 양질의 데이터가 묶여있는 카테고리를 찾기도 어려웠고 , 크롤링도 상당히 비효율적일것이라 생각하였습니다.\n",
    "- ko-wiki dump 파일이나 , FastText pre-trained model을 가져오려고 하였으나 , 성능이 상당히 좋지 않을 것 같아서 , 새로운 데이터로 새로운 모델을 구축하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "#외부에서 직접 Crawling 해온 데이터들\n",
    "def loadCralwlingData():\n",
    "    회계 = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/회계세무.csv', index_col = 0)\n",
    "    음식 = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/음식.csv', index_col = 0)\n",
    "    부동산 = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/부동산.csv', index_col = 0)\n",
    "    HRD = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/HRD.csv', index_col = 0)\n",
    "    무역 = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/무역.csv', index_col = 0)\n",
    "    통계 = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/통계.csv', index_col = 0)\n",
    "    건축 = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/건축.csv', index_col = 0)\n",
    "    숙박 = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/숙박.csv', index_col = 0)\n",
    "    음식점  = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/정제brand_name.csv', index_col = 0)\n",
    "    생활취미  = pd.read_csv('/home/jovyan/WIDE_HOME/CrawlingData/생활취미.csv', index_col = 0)\n",
    "    \n",
    "    \n",
    "    re_pattern = re.compile(r'[^ 가-힣a-zA-Z0-9]')\n",
    "\n",
    "    trnDF = pd.concat([회계,음식,부동산,HRD, 무역,통계, 건축, 숙박, 음식점, 생활취미], ignore_index = True)\n",
    "    \n",
    "    return trnDF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def refineTrainDF(trnDF):\n",
    "    re_pattern = re.compile(r'[^ 가-힣a-zA-Z0-9]')\n",
    "    \n",
    "    trnDF['words'] = trnDF['0'].apply(lambda x : re.sub(pattern = re_pattern , repl = '', string = str(x)))\n",
    "    trnDF['words'] = trnDF['words'].apply(lambda x : m.nouns(x))\n",
    "    \n",
    "    trnDF.drop('0', axis = 1 , inplace = True)\n",
    "    \n",
    "    #위에서 생성한 적요데이터 5음절 이상인 단어로 학습용데이터로 활용\n",
    "    finalSent = pd.concat([trnDF['words'] , useDataSent], ignore_index = True)\n",
    "    \n",
    "    return finalSent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최종적으로 학습에 사용될 데이터 셋 정제 및 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnDF = loadCralwlingData()\n",
    "finalSent = refineTrainDF(trnDF)\n",
    "\n",
    "\n",
    "finalSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "size = 200\n",
    "window = 5\n",
    "\n",
    "model = FastText(sentences = finalSent.values, size = size, window = window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FastText를 활용한 Embedding 모델링 잘 되었나 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('피자')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('바닥자재공사')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 대회에서 주어진 Container 환경의 RAM 성능 한계로 인해 , 전체522만개의 행 중 , 랜덤 30000개의 행을 사용하여 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "maxRow = 30000 #모든 데이터프레임 써주고싶지만 , 사양문제로 제한적\n",
    "\n",
    "randomRow = [random.randint(0, df.shape[0]) for i in range(maxRow)]\n",
    "\n",
    "briefVector= pd.DataFrame(df.loc[randomRow, '적요'].apply(lambda x : model.wv.word_vec(x).tolist()))\n",
    "\n",
    "trainDF = pd.DataFrame(briefVector['적요'].tolist())\n",
    "mergeDF =  df.loc[randomRow , ['판매구매자_업종중분류','구매/판매구분','적요']].reset_index().drop('index', axis = 1)\n",
    "trainDF = pd.concat([trainDF, mergeDF] , axis = 1)\n",
    "trainDF = pd.get_dummies(trainDF, columns = ['판매구매자_업종중분류'])\n",
    "\n",
    "trainDF\n",
    "\n",
    "del briefVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = trainDF.loc[ : , : '구매/판매구분'].values\n",
    "\n",
    "X = trainDF.drop('적요', axis = 1).values\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- __적요 임베딩한 200개의 차원__과 , __구매/판매구분__ , __업종 중분류__ One-hot Encoding하여 , 총 263개의 Column 학습\n",
    "- RAM의 사양 한계로 인해 랜덤으로 추출한 30000 개의 행의 데이터만 군집화가 가능하였습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>K-means Clustering</center>\n",
    "\n",
    "- cluster를 정하는 데에 있어서 많은 고민을 하였습니다.\n",
    "- 실루엣계수를 통해 최적의 군집수를 구해보려 했지만 , 군집의수를 최대한 많이 해서 직접 수작업으로 비슷한 특성을 가진 군집끼리 Labeling 것이 더 정확한 군집화가 가능할 것이라 생각하였습니다. 작업 속도를 위하여 K-means Clustering을 사용하였습니다.\n",
    "- parameter 는 클러스터 수 외에는 크게 변경하지 않았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_cluster = 30\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_cluster, init='k-means++' ,verbose = 1, random_state = 2020)\n",
    "label = kmeans.fit_predict(X)\n",
    "\n",
    "trainDF['Label'] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 군집화 잘 되었는지 , 각 군집별 분포로 확인\n",
    "\n",
    "- 군집의 이름을 Labeling을 하고싶었는데 , 이 작업에서는 시간이 부족하기도 하였고 , 군집의 수를 늘리면 커널이 자꾸 종료되었습니다 . \n",
    "- 만약에 커널의 성능이 뒷받침이 되었다면 , Cluster의 개수를 상당히 늘려서 , 클러스터링 후 , 군집들을 직접 Labeling 해줄 예정이였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_cluster):\n",
    "    \n",
    "    plt.figure(figsize = (20,4))\n",
    "    trainDF.loc[trainDF['Label'] == n]['적요'].value_counts().head(30).plot(kind = 'bar')\n",
    "    plt.title(str(n) + ' 번 군집의 count : ' +str(trainDF.loc[trainDF['Label'] == n].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> t-Stochastic Neighbor Embedding (t-SNE)</center>\n",
    "\n",
    "- 시각화를 위하여 고차원 데이터의 차원을 축소하는 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "\n",
    "# t-SNE 모델 생성 및 학습\n",
    "\n",
    "tsne = TSNE(random_state=0)\n",
    "\n",
    "digits_tsne = tsne.fit_transform(X)\n",
    "\n",
    "\n",
    "colors = []\n",
    " \n",
    "#t-SNE 로 시각화할때 , 군집별로 색깔 다르게 표현\n",
    "for i in range(n_cluster):\n",
    "    colors.append('#%06X' % random.randint(0, 0xFFFFFF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### t-SNE를 활용하여 , 군집별로 색깔을 다르게 하여 , 군집화가 잘 되었는지 확인하기 위한 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "plt.figure(figsize = (80,55))\n",
    "\n",
    "for i in tqdm(range(len(X))): # 0부터  X까지 정수\n",
    "    plt.text(digits_tsne[i, 0], digits_tsne[i, 1], str(trainDF.loc[i, '적요']), # x, y , 그룹\n",
    "\n",
    "             color=colors[trainDF['Label'][i]], # 색상\n",
    "\n",
    "             fontdict={'weight': 'bold', 'size':27}) # font\n",
    "    \n",
    "    \n",
    "    #너무 많은 데이터 사용하면 , 시각적으로 보기 오히려 더 힘들어져서 150개의 행만 사용하여 시각화\n",
    "    if i ==150:\n",
    "        break\n",
    "\n",
    "plt.xlim(digits_tsne[:, 0].min(), digits_tsne[:, 0].max()) # 최소, 최대\n",
    "\n",
    "plt.ylim(digits_tsne[:, 1].min(), digits_tsne[:, 1].max()) # 최소, 최대\n",
    "\n",
    "plt.xlabel('t-SNE 특성0') # x축 이름\n",
    "\n",
    "plt.ylabel('t-SNE 특성1') # y축 이름\n",
    "\n",
    "plt.show() # 그래프 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>보완 가능 점 및 고찰</center>\n",
    "- RAM 이 최대 16GB로 제한이 되어 있는 점으로 인해 커널이 터져버리는 경우가 상당히 많이 발생하였습니다. 이러한 문제로 전체 적요 데이터 522만개의 데이터 중 3만개의 데이터로만 군집화를 진행하였습니다 . \n",
    "<br><br>\n",
    "\n",
    "- 모델에 사용할 데이터를 더 구한다면 더 좋아질 것 같습니다 . 위키피디아나 나무위키의 데이터를 대량 학습을 시키고 싶었으나 , RAM 용량의 한계로 인해 학습을 시키는데에 문제가 생길 것 같아 크롤링데이터는 저희가 생각하기에 최대한 필요한 양질의 데이터만을 활용하였습니다.\n",
    "<br><br>\n",
    "- 램의 사용량에 큰 문제가 없었다면 , 군집의 수를 상당히 크게 잡아서 , 비슷한 군집끼리 직접 Labeling을 진행해주고 싶었습니다. 하지만 성능의 한계로 인해 , 군집의 수를 많이 늘리지 못하였고 , 그래서 군집의 경계가 상당히 모호해져 , 군집들의 이름을 명확히 지어주는데에 있어서 어려움을 많이 겪었습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
